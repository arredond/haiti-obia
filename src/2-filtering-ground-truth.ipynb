{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from shapely.wkt import loads\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "latlon = {'init': 'epsg:4326'}\n",
    "utm_18 = {'init': 'epsg:32618'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Ground Truth and samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_all = pd.read_excel('/Users/arredond/Downloads/GT_Depuration_v1.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rename the common fields to make this easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_all.rename(index=str, columns={\n",
    "    \"Nombre d'étage\": 'stories',\n",
    "    \"Superficie approximative\": 'area'\n",
    "}, inplace=True)\n",
    "gt_all.columns = gt_all.columns.map(str.lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types\n",
    "\n",
    "| **MBT short** | **MBT full** | **Structure material**               | **Wall material**                                           |\n",
    "| ------------- | ------------ | ------------------------------------ | ----------------------------------------------------------- |\n",
    "| MandW         | CM-UM        | Murs porteurs               | Blocs OR briques OR matonnerie de roches OR bois&matonnerie |\n",
    "| RC            | RC-CB        | Béton OR béton armé                  | Blocs                                       |\n",
    "| RC            | RC-SW        | Murs porteurs OR béton OR béton armé | Béton armé                                                  |\n",
    "| RC            | RC-UM        | Béton armé                           | Briques OR matonnerie de roches OR bois&matonnerie            |\n",
    "| RC            | RL-BM        | Murs porteurs                        | Blocs armés                                                 |\n",
    "| MandW         | W-UM         | Bois&Tole                            | Blocs OR briques OR matonnerie de roches OR bois&matonnerie |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_dict = {\n",
    "    'W-UM': {\n",
    "        'idx': (gt_all['structure'] == 'Structure en bois et en tole') & gt_all['murs'].isin([\n",
    "                    'Murs de blocs non armés',\n",
    "                    'Murs de briques',\n",
    "                    'Maτonnerie de roches',\n",
    "                    'Bois + Maτonnerie'\n",
    "                ]),\n",
    "        'ts': 'MAndW'\n",
    "    },\n",
    "    'RL-BM': {\n",
    "        'idx': (gt_all['structure'] == 'Murs porteurs') & (gt_all['murs'] == 'Murs de blocs armés'),\n",
    "        'ts': 'RC'\n",
    "    },\n",
    "    'RC-UM': {\n",
    "        'idx': (gt_all['structure'] == 'Structure en béton armé') & gt_all['murs'].isin([\n",
    "            'Murs de briques',\n",
    "            'Maτonnerie de roches',\n",
    "            'Bois + Maτonnerie'\n",
    "        ]),\n",
    "        'ts': 'RC'\n",
    "    },\n",
    "    'RC-SW': {\n",
    "        'idx': (gt_all['structure'].isin([\n",
    "            'Murs porteurs',\n",
    "            'Structure en béton',\n",
    "            'Structure en béton armé'\n",
    "        ])) & (gt_all['murs'] == 'Murs en béton armé'),\n",
    "        'ts': 'RC'\n",
    "    },\n",
    "    'RC-CB': {\n",
    "        'idx': (gt_all['structure'].isin([\n",
    "            'Structure en béton',\n",
    "            'Structure en béton armé'\n",
    "        ])) & (gt_all['murs'].isin([\n",
    "            'Murs de blocs non armés'\n",
    "        ])),\n",
    "        'ts': 'RC'\n",
    "    },\n",
    "    'CM-UM': {\n",
    "        'idx': (gt_all['structure'].isin([\n",
    "            'Murs porteurs'\n",
    "        ])) & (gt_all['murs'].isin([\n",
    "            'Murs de blocs non armés',\n",
    "            'Murs de briques',\n",
    "            'Maτonnerie de roches',\n",
    "            'Bois + Maτonnerie'\n",
    "        ])),\n",
    "        'ts': 'MAndW'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add MBTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_all['type_short'] = None\n",
    "gt_all['type_full'] = None\n",
    "for k,v in types_dict.items():\n",
    "    gt_all.loc[v['idx'], 'type_full'] = k\n",
    "    gt_all.loc[v['idx'], 'type_short'] = v['ts']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data\n",
    "\n",
    "- Remove records that aren't `residential`\n",
    "- Remove records with 100% damage\n",
    "- Remove records with empty cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_all = gt_all.loc[\n",
    "    (gt_all['residentiel- section unique'] == 'X') |\n",
    "    (gt_all['residentiel- section multiple'] == 'X')\n",
    "].drop(axis=1, columns=['residentiel- section unique', 'residentiel- section multiple'])\n",
    "\n",
    "gt_all = gt_all.loc[~(gt_all['dommage estimé'] == '100%')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vital_cols = [\n",
    "    \"stories\", \"area\", \"toiture\", \"structure\", \"murs\",\n",
    "    \"quartier\", \"type_full\", \"type_short\"\n",
    "]\n",
    "gt_all.dropna(axis=0, subset=vital_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Filter area, keeping only 0 <= area <= 250  (sqm)\n",
    "- Filter height, keeping only 0 <= height <= 25  (m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_conditions = [\n",
    "    'area >= 10',\n",
    "    'area <= 250',\n",
    "    'stories >= 0',\n",
    "    'stories <= 8'\n",
    "]\n",
    "\n",
    "gt_all = gt_all.query(' & '.join(filter_conditions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Eliminate records where RoofType = RC and type_short = MandW\n",
    "* Eliminate records where RoofType = Tin and area < 20 and Stories < 1 and type_short = RC\n",
    "* Eliminate records where RoofType = Tin and area > 200 and Stories >= 2 and type_short = MandW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_all['roof_type'] = gt_all['toiture'].apply(lambda x: 'tin' if 'tole' in x.lower() else 'rc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\\\n",
    "    (roof_type != 'rc' | type_short != 'MAndW') & \\\n",
    "    (roof_type != 'tin' | type_short != 'RC' | area >= 20 | stories >= 1) & \\\n",
    "    (roof_type != 'tin' | type_short != 'MAndW' | area <= 200)\"\n",
    "gt_all = gt_all.query(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to GeoDataFrame in order to get the urban pattern for each point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_all['geometry'] = gt_all.apply(lambda row: Point(row['longitude'], row['latitude']), axis=1)\n",
    "gt_all = gpd.GeoDataFrame(gt_all.copy())\n",
    "gt_all.crs = latlon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll convert the coordinates in UTM Zone 18N for model and visualization purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_all = gt_all.to_crs(utm_18)\n",
    "gt_all['utm_x'] = gt_all.geometry.x\n",
    "gt_all['utm_y'] = gt_all.geometry.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load urban patterns and intersect to add to GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "urban_patterns = gpd.read_file(\"../data/urban_patterns/UrbanPattern_PauP_Complete.shp\")\n",
    "urban_patterns.rename(index=str, columns={'UrbanPatte': 'pattern'}, inplace=True)\n",
    "urban_patterns.replace('Informal', 'Shanty', inplace=True)\n",
    "urban_patterns = urban_patterns.to_crs(gt_all.crs)\n",
    "\n",
    "gt_sjoin = gpd.sjoin(gt_all, urban_patterns[['geometry', 'pattern']], op='within')\n",
    "\n",
    "# Keep only the Urban Patterns we're interested in\n",
    "gt_sjoin = gt_sjoin.loc[~gt_sjoin['pattern'].isin(['No', 'Industrial'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a clean-but-complete Ground Truth.\n",
    "Let's save this as vector and CSV before proceding\n",
    "to reduce the number of fields and rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_sjoin.to_csv(\"../data/ground_truth/ground_truth_clean.csv\", index=False)\n",
    "gt_sjoin.to_file(\"../data/ground_truth/ground_truth_clean.gpkg\", driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keeping only the necessary data\n",
    "\n",
    "First of all, let's just keep the columns we _really_ want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cols = [\n",
    "    'stories', 'area', 'roof_type', 'quartier',\n",
    "    'type_full', 'type_short', 'pattern', 'geometry',\n",
    "    'latitude', 'longitude', 'utm_x', 'utm_y'\n",
    "]\n",
    "gt = gt_sjoin.loc[:, min_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll remove all GT points inside samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load samples\n",
    "samples = pd.read_csv(\"../data/samples/samples_reference.csv\")\n",
    "samples['geometry'] = samples['geometry_wkt'].apply(lambda x: loads(x))\n",
    "samples = gpd.GeoDataFrame(samples, crs=latlon)\n",
    "samples = samples.to_crs(crs=utm_18)\n",
    "samples = samples.loc[~samples['FID'].isin([10, 17, 22])]\n",
    "samples['Class'] = samples['Class'].str.lower()\n",
    "samples = samples[['FID', 'Class', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UrbanIrreg (752, 14)\n",
      "UrbanReg (679, 14)\n",
      "Shanty (952, 14)\n",
      "Rural (67, 14)\n",
      "Residential (116, 14)\n"
     ]
    }
   ],
   "source": [
    "intersect = gpd.sjoin(gt, samples, op='within').set_index('index_right')\n",
    "\n",
    "# Keep samples within for model classification\n",
    "os.makedirs('../data/ground_truth/within_samples', exist_ok=True)\n",
    "for stratum in intersect['pattern'].unique():\n",
    "    stratum_within = intersect.loc[intersect['pattern'] == stratum]\n",
    "    print(stratum, stratum_within.shape)\n",
    "    stratum_within.to_file(f'../data/ground_truth/within_samples/gt_within_{stratum.lower()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use samples outside for model training\n",
    "gt = gt.loc[np.invert(gt.index.isin(intersect.index)), :].copy()\n",
    "gt.reset_index(inplace=True)\n",
    "gt.drop(axis=1, columns=['geometry', 'index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = ['UrbanReg', 'UrbanIrreg', 'Shanty', 'Residential', 'Rural']\n",
    "selected = {}\n",
    "\n",
    "for p in patterns:\n",
    "    gt_pattern = gt.loc[gt['pattern'] == p, :]\n",
    "    print(f'{p}: {len(gt_pattern)} (Total) - {len(gt_pattern.loc[gt_pattern[\"type_short\"] == \"MAndW\"])} (MAndW) - {len(gt_pattern.loc[gt_pattern[\"type_short\"] == \"RC\"])} (RC)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep a testing/training set for each urban pattern.\n",
    "We'll keep the classes balanced to help the latter models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../data/ground_truth/outside_samples', exist_ok=True)\n",
    "\n",
    "patterns = ['UrbanReg', 'UrbanIrreg', 'Shanty', 'Residential', 'Rural']\n",
    "selected = {}\n",
    "\n",
    "for p in patterns:\n",
    "    if p == 'Rural':\n",
    "        n, n_train, n_test = 150, 120, 30\n",
    "    elif p == 'Residential':\n",
    "        n, n_train, n_test = 300, 240, 60\n",
    "    elif p == 'UrbanReg':\n",
    "        n, n_train, n_test = 2000, 1600, 400\n",
    "    else:\n",
    "        n, n_train, n_test = 4000, 3200, 800\n",
    "\n",
    "    gtp = gt.loc[gt['pattern'] == p, :]\n",
    "    \n",
    "    # Save without sampling (unbalanced)\n",
    "    gtp_train_unb = gtp.copy().sample(round(gtp.shape[0]*0.8))\n",
    "    gtp_test_unb = gtp.copy().loc[~gtp.index.isin(gtp_train_unb.index), :]\n",
    "    \n",
    "    # Sample balanced\n",
    "    gtp_mw = gtp.loc[gt['type_short'] == 'MAndW', :].sample(n)\n",
    "    gtp_rc = gtp.loc[gt['type_short'] == 'RC', :].sample(n)\n",
    "    \n",
    "    selected[p] = {\n",
    "        'train': pd.concat([\n",
    "            gtp_mw.head(n_train),\n",
    "            gtp_rc.head(n_train)\n",
    "        ], ignore_index=True),\n",
    "        'test': pd.concat([\n",
    "            gtp_mw.tail(n_test),\n",
    "            gtp_rc.tail(n_test)\n",
    "        ], ignore_index=True),\n",
    "        'train_unbalanced': gtp_train_unb,\n",
    "        'test_unbalanced': gtp_test_unb\n",
    "    }\n",
    "    \n",
    "    \n",
    "    for k,v in selected[p].items():\n",
    "        v.to_csv(f'../data/ground_truth/outside_samples/gt_{p.lower()}_{k}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All together now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also keep a copy of all the data together, in order to test the models\n",
    "in other, exciting ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train_data = {\n",
    "    'test': pd.concat([selected[x]['test'] for x in selected.keys()]),\n",
    "    'train': pd.concat([selected[x]['train'] for x in selected.keys()])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in test_train_data.items():\n",
    "    v.to_csv(f'../data/ground_truth/gt_{k}_all.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
