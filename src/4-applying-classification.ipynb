{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying classification\n",
    "\n",
    "Applying Ground Truth models to both digitized and segmentized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "from scipy.spatial.distance import pdist, cdist, squareform\n",
    "from shapely.geometry import Point\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PUK_kernel(X1,X2, sigma, omega):\n",
    "    \"\"\"Compute the kernel matrix between two arrays using the Pearson VII function-based universal kernel.\n",
    "    From: @rlphilli - https://github.com/rlphilli/sklearn-PUK-kernel/blob/master/PUK_kernel.py\n",
    "    \"\"\"\n",
    "    # Compute squared euclidean distance between each row element pair of the two matrices\n",
    "    if X1 is X2 :\n",
    "        kernel = squareform(pdist(X1, 'sqeuclidean'))\n",
    "    else:\n",
    "        kernel = cdist(X1, X2, 'sqeuclidean')\n",
    "\n",
    "    kernel = (1 + (kernel * 4 * np.sqrt(2**(1.0/omega)-1)) / sigma**2) ** omega\n",
    "    kernel = 1/kernel\n",
    "\n",
    "    return kernel\n",
    "\n",
    "def assign_stratum(sample_id, strata_samples):\n",
    "    for stratum, fids in strata_samples.items():\n",
    "        for fid in fids:\n",
    "            if int(sample_id) == int(fid):\n",
    "                return stratum\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load models and scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = '../data/results/models'\n",
    "scalers_path = '../data/results/scalers'\n",
    "\n",
    "strata_samples = {\n",
    "    'residential': [13, 6, 0, 23, 8],\n",
    "    'rural': [5, 19],\n",
    "    'shanty': [3, 9, 2],\n",
    "    'urbanirreg': [21, 15, 18, 16],\n",
    "    'urbanreg': [11, 20, 4, 1, 7, 14, 12]\n",
    "}\n",
    "blacklist = [str(x) for x in [10, 17, 22]]\n",
    "scalers = {stratum:load(os.path.join(scalers_path, f'{stratum}_scaler.joblib')) for stratum in strata_samples.keys()}\n",
    "\n",
    "models = {stratum:{} for stratum in strata_samples.keys()}\n",
    "for stratum in strata_samples.keys():\n",
    "    for model_name in [m for m in os.listdir(models_path) if m.startswith(stratum)]:\n",
    "        model_name_short = model_name.replace(f'{stratum}_', '').replace('_model.joblib', '')\n",
    "        models[stratum][model_name_short] = load(os.path.join(models_path, model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digitized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_path = '../data/results/classified'\n",
    "os.makedirs(classified_path, exist_ok=True)\n",
    "\n",
    "digitized = {k:gpd.read_file(f'../data/Digitization/output/FID_{k}_digi_elev.gpkg') for k in range(24) if k not in blacklist}\n",
    "digitized = {stratum:pd.concat([digitized[k] for k in strata_samples[stratum]]) for stratum in strata_samples.keys()}\n",
    "\n",
    "digi_predictions = {}\n",
    "for stratum, digi_df in digitized.items():\n",
    "    df = digi_df.copy()\n",
    "    df.loc[:, 'area'] = df.geometry.area\n",
    "    df['roof_type'] = df['Roof'].str.lower()\n",
    "    df['stories'] = df['mean']/3\n",
    "    df['utm_x'] = df.geometry.centroid.x\n",
    "    df['utm_y'] = df.geometry.centroid.y\n",
    "    df = df.loc[(df['area'] > 10) & (df['stories'] > 0.5)]\n",
    "    df.dropna(subset=['stories', 'area', 'roof_type', 'utm_x', 'utm_y'], inplace=True)\n",
    "    \n",
    "    # Select columns and scale\n",
    "    df_x = df.loc[:, ['stories', 'area', 'roof_type', 'utm_x', 'utm_y']].copy()\n",
    "    df_x = pd.get_dummies(df_x)\n",
    "    for col in df_x.columns:\n",
    "        df_x[col] = df_x[col].astype(np.float64)\n",
    "    df_scaled = StandardScaler().fit_transform(df_x)\n",
    "    \n",
    "    # Apply classifier and save result in original DF\n",
    "    for model, clf in models[stratum].items():\n",
    "        df[f'class_{model}'] = clf.predict(df_scaled)\n",
    "    \n",
    "    # Save as CSV and also GPKG\n",
    "    df.to_csv(os.path.join(classified_path, f'{stratum}_digitized.csv'), index=False)\n",
    "    df.to_file(os.path.join(classified_path, f'{stratum}_digitized.gpkg'), driver='GPKG')\n",
    "    digi_predictions[stratum] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentized_all = gpd.read_file('../data/results/rgb_elev_segm.gpkg')\n",
    "\n",
    "segmentized_all['sample_id'] = segmentized_all['segment_id'].str.split('_').str[0]\n",
    "segmentized_all['stratum'] = segmentized_all['sample_id'].apply(assign_stratum, strata_samples=strata_samples)\n",
    "segmentized_all = segmentized_all.loc[segmentized_all['class_right'].isin(['concrete', 'tin'])]\n",
    "segmentized_all['roof_type'] = segmentized_all['class_right'].replace({'concrete': 'rc'})\n",
    "\n",
    "segmentized_all = segmentized_all.loc[(segmentized_all['area'] > 10) & (segmentized_all['stories'] > 0.5)]\n",
    "\n",
    "segmentized = {k:segmentized_all.loc[segmentized_all['stratum'] == k] for k in strata_samples.keys()}\n",
    "segm_predictions = {}\n",
    "for stratum, segm_df in segmentized.items():\n",
    "    df = segm_df.copy()\n",
    "    df.dropna(subset=['stories', 'area', 'roof_type', 'utm_x', 'utm_y'], inplace=True)\n",
    "    \n",
    "    # Select columns and scale\n",
    "    df_x = df.loc[:, ['stories', 'area', 'roof_type', 'utm_x', 'utm_y']].copy()\n",
    "    df_x = pd.get_dummies(df_x)\n",
    "    for col in df_x.columns:\n",
    "        df_x[col] = df_x[col].astype(np.float64)\n",
    "    df_scaled = StandardScaler().fit_transform(df_x)\n",
    "    \n",
    "    # Apply classifier and save result in original DF\n",
    "    for model, clf in models[stratum].items():\n",
    "        df[f'class_{model}'] = clf.predict(df_scaled)\n",
    "    \n",
    "    # Save as CSV and also GPKG\n",
    "    df.to_csv(os.path.join(classified_path, f'{stratum}_segmentized.csv'), index=False)\n",
    "    df.to_file(os.path.join(classified_path, f'{stratum}_segmentized.gpkg'), driver='GPKG')\n",
    "    segm_predictions[stratum] = df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
